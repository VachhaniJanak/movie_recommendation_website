{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:15:21.839590Z","iopub.status.busy":"2024-09-25T16:15:21.838941Z","iopub.status.idle":"2024-09-25T16:15:35.002574Z","shell.execute_reply":"2024-09-25T16:15:35.001436Z","shell.execute_reply.started":"2024-09-25T16:15:21.839548Z"},"trusted":true},"outputs":[],"source":["# !pip install torcheval"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:15:35.005796Z","iopub.status.busy":"2024-09-25T16:15:35.005340Z","iopub.status.idle":"2024-09-25T16:15:35.011976Z","shell.execute_reply":"2024-09-25T16:15:35.010754Z","shell.execute_reply.started":"2024-09-25T16:15:35.005745Z"},"id":"8kywR1CCyW18","trusted":true},"outputs":[],"source":["import pandas as pd\n","from sklearn import model_selection\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from sklearn.metrics import precision_score, recall_score"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:15:35.013663Z","iopub.status.busy":"2024-09-25T16:15:35.013316Z","iopub.status.idle":"2024-09-25T16:15:35.026771Z","shell.execute_reply":"2024-09-25T16:15:35.025819Z","shell.execute_reply.started":"2024-09-25T16:15:35.013622Z"},"id":"7jOZ2h1FyW1_","trusted":true},"outputs":[{"data":{"text/plain":["device(type='cpu')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","device"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-25T16:15:35.029677Z","iopub.status.busy":"2024-09-25T16:15:35.029294Z","iopub.status.idle":"2024-09-25T16:15:37.484260Z","shell.execute_reply":"2024-09-25T16:15:37.483198Z","shell.execute_reply.started":"2024-09-25T16:15:35.029620Z"},"id":"Dr7PfpUhyW2A","outputId":"b6b59870-d96f-4c11-eb8f-231006ec880b","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7813737 entries, 0 to 7813736\n","Data columns (total 3 columns):\n"," #   Column    Dtype\n","---  ------    -----\n"," 0   user_id   int64\n"," 1   anime_id  int64\n"," 2   rating    int64\n","dtypes: int64(3)\n","memory usage: 178.8 MB\n"]}],"source":["df = pd.read_csv(\"data/rating.csv\")\n","df.info()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-25T16:15:37.486573Z","iopub.status.busy":"2024-09-25T16:15:37.485963Z","iopub.status.idle":"2024-09-25T16:15:37.536060Z","shell.execute_reply":"2024-09-25T16:15:37.535167Z","shell.execute_reply.started":"2024-09-25T16:15:37.486538Z"},"id":"zihm8wnIyW2C","outputId":"196c892d-22da-4b0d-f1c1-a5b98a6a0158","trusted":true},"outputs":[{"data":{"text/plain":["73515"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.user_id.nunique()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":429},"execution":{"iopub.execute_input":"2024-09-25T16:15:37.537548Z","iopub.status.busy":"2024-09-25T16:15:37.537256Z","iopub.status.idle":"2024-09-25T16:15:37.605672Z","shell.execute_reply":"2024-09-25T16:15:37.604654Z","shell.execute_reply.started":"2024-09-25T16:15:37.537517Z"},"id":"VUkt5HqyyW2C","outputId":"ea340547-f643-4c50-db9e-850be80cb666","trusted":true},"outputs":[{"data":{"text/plain":["rating\n"," 8     1646019\n","-1     1476496\n"," 7     1375287\n"," 9     1254096\n"," 10     955715\n"," 6      637775\n"," 5      282806\n"," 4      104291\n"," 3       41453\n"," 2       23150\n"," 1       16649\n","Name: count, dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.rating.value_counts()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:15:37.607710Z","iopub.status.busy":"2024-09-25T16:15:37.606846Z","iopub.status.idle":"2024-09-25T16:15:37.615736Z","shell.execute_reply":"2024-09-25T16:15:37.614761Z","shell.execute_reply.started":"2024-09-25T16:15:37.607666Z"},"id":"JqqeD7X6yW2D","trusted":true},"outputs":[],"source":["class MovieDataset:\n","    def __init__(self, users, movies, ratings) -> None:\n","        self.users = users\n","        self.movies = movies\n","        self.ratings = ratings\n","\n","    def __len__(self):\n","        return len(self.users)\n","\n","    def __getitem__(self, idx):\n","        users = self.users[idx]\n","        movies = self.movies[idx]\n","        ratings = self.ratings[idx]\n","\n","        return {\n","            \"users\":torch.tensor(users, dtype=torch.long).to(device),\n","            \"movies\":torch.tensor(movies, dtype=torch.long).to(device),\n","            \"rating\":torch.tensor(ratings, dtype=torch.long).to(device),\n","        }"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:15:37.617287Z","iopub.status.busy":"2024-09-25T16:15:37.616940Z","iopub.status.idle":"2024-09-25T16:15:37.630228Z","shell.execute_reply":"2024-09-25T16:15:37.629329Z","shell.execute_reply.started":"2024-09-25T16:15:37.617246Z"},"trusted":true},"outputs":[],"source":["### Demo Model\n","\n","class HashEmbedding(nn.Module):\n","    def __init__(self, num_buckets, embedding_dim):\n","        \"\"\"\n","        num_buckets: Number of buckets (fixed number of embedding vectors).\n","        embedding_dim: Dimension of each embedding vector.\n","        \"\"\"\n","        super(HashEmbedding, self).__init__()\n","        self.num_buckets = num_buckets\n","        self.embedding_dim = embedding_dim\n","        \n","        # Embedding layer with a fixed number of buckets\n","        self.embeddings = nn.Embedding(num_buckets, embedding_dim)\n","        \n","    def forward(self, ids):\n","        \"\"\"\n","        ids: Tensor of user or item IDs.\n","        \"\"\"\n","        # Hash the IDs to the range of available buckets\n","        hashed_ids = ids % self.num_buckets\n","        \n","        # Retrieve the corresponding embeddings for the hashed IDs\n","        return self.embeddings(hashed_ids) "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:15:37.631714Z","iopub.status.busy":"2024-09-25T16:15:37.631408Z","iopub.status.idle":"2024-09-25T16:15:37.673807Z","shell.execute_reply":"2024-09-25T16:15:37.672902Z","shell.execute_reply.started":"2024-09-25T16:15:37.631683Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["IDs: tensor([1001, 2002, 3003])\n","Hashed IDs: tensor([1, 0, 1])\n"]}],"source":["# Parameters\n","num_buckets = 2  # Number of embedding buckets (buckets size)\n","embedding_dim = 16  # Dimension of each embedding vector\n","\n","# Instantiate the hash embedding model\n","hash_embedding = HashEmbedding(num_buckets, embedding_dim)\n","\n","# Sample user or movie IDs\n","ids = torch.tensor([1001, 2002, 3003])  # Example entity IDs\n","\n","# Perform embedding lookup using hashing\n","embeddings = hash_embedding(ids)\n","\n","print(\"IDs:\", ids)\n","print(\"Hashed IDs:\", ids % num_buckets)\n","# print(\"Embeddings:\", embeddings)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T17:57:56.479162Z","iopub.status.busy":"2024-09-25T17:57:56.478838Z","iopub.status.idle":"2024-09-25T17:57:56.492304Z","shell.execute_reply":"2024-09-25T17:57:56.491391Z","shell.execute_reply.started":"2024-09-25T17:57:56.479118Z"},"id":"V-2eyUmpyW2D","trusted":true},"outputs":[],"source":["class RecSysModelWithDropout(nn.Module):\n","    def __init__(self, users_buckets, movies_buckets, embedding_dim=32):\n","        super().__init__()\n","\n","        self.users_buckets = users_buckets\n","        self.movies_buckets = movies_buckets\n","\n","        self.user_embed = nn.Embedding(users_buckets, embedding_dim, sparse=True)\n","        self.movie_embed = nn.Embedding(movies_buckets, embedding_dim, sparse=True)\n","        \n","        # self.user_biases = torch.nn.Embedding(users_buckets, 1, sparse=True)\n","        # self.item_biases = torch.nn.Embedding(movies_buckets, 1, sparse=True)\n","\n","        self.user_embed.weight.data.uniform_(-0.05, 0.05)\n","        self.movie_embed.weight.data.uniform_(-0.05, 0.05)\n","\n","        self.dropout0 = nn.Dropout(0.5)\n","        self.dropout1 = nn.Dropout(0.5)\n","\n","        self.m = torch.nn.Sigmoid()\n","\n","    def forward(self, users_ids, movies_ids):\n","        hashed_users_ids = users_ids % self.users_buckets\n","        hashed_movies_ids = movies_ids % self.movies_buckets\n","        \n","        user_embed = self.user_embed(hashed_users_ids)\n","        movie_embed = self.movie_embed(hashed_movies_ids)\n","\n","        output = (self.dropout0(user_embed) * self.dropout1(movie_embed)).sum(1)# + self.user_biases(hashed_users_ids).sum(1) + self.item_biases(hashed_movies_ids).sum(1)\n","        return self.m(output)\n","\n","    \n","    def expand_embeddings(self, users_buckets, movies_buckets):\n","        \"\"\"\n","        Expand the embedding table to accommodate more embeddings.\n","        new_num_embeddings: New total number of embeddings after expansion.\n","        \"\"\"\n","        if users_buckets > self.users_buckets:        \n","            # Create a new embedding layer with the expanded size\n","            new_user_embed = nn.Embedding(users_buckets, self.embedding_dim)\n","        \n","            # Copy the old embeddings into the new expanded layer\n","            with torch.no_grad():\n","                new_user_embed.weight[:self.users_buckets] = self.user_embed.weight\n","                self.user_embed = new_user_embed\n","                self.users_buckets = users_buckets\n","\n","        if movies_buckets > self.movies_buckets:\n","            # Create a new embedding layer with the expanded size\n","            new_movie_embed = nn.Embedding(movies_buckets, self.embedding_dim)\n","        \n","            # Copy the old embeddings into the new expanded layer\n","            with torch.no_grad():\n","                new_movie_embed.weight[:self.movies_buckets] = self.movie_embed.weight\n","                self.movie_embed = new_movie_embed\n","                self.movies_buckets = movies_buckets"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-25T16:15:37.690886Z","iopub.status.busy":"2024-09-25T16:15:37.690528Z","iopub.status.idle":"2024-09-25T16:15:37.703836Z","shell.execute_reply":"2024-09-25T16:15:37.702938Z","shell.execute_reply.started":"2024-09-25T16:15:37.690831Z"},"id":"VVT4dMoOyW2D","outputId":"8cd2e25d-3e47-47d0-c75a-964f56056c7d","trusted":true},"outputs":[{"data":{"text/plain":["array([    1,     1,     1, ..., 73515, 73516, 73516])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df.user_id.values"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:15:37.705745Z","iopub.status.busy":"2024-09-25T16:15:37.705259Z","iopub.status.idle":"2024-09-25T16:15:37.714963Z","shell.execute_reply":"2024-09-25T16:15:37.713931Z","shell.execute_reply.started":"2024-09-25T16:15:37.705695Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['user_id', 'anime_id', 'rating'], dtype='object')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.keys()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:15:37.716847Z","iopub.status.busy":"2024-09-25T16:15:37.716223Z","iopub.status.idle":"2024-09-25T16:15:37.796649Z","shell.execute_reply":"2024-09-25T16:15:37.795656Z","shell.execute_reply.started":"2024-09-25T16:15:37.716784Z"},"trusted":true},"outputs":[],"source":["df.rating = (df.rating/2).astype(int)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:15:38.323542Z","iopub.status.busy":"2024-09-25T16:15:38.323158Z","iopub.status.idle":"2024-09-25T16:15:38.540610Z","shell.execute_reply":"2024-09-25T16:15:38.539682Z","shell.execute_reply.started":"2024-09-25T16:15:38.323504Z"},"trusted":true},"outputs":[],"source":["df.rating = (df.rating / 3.5).astype(int)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>anime_id</th>\n","    </tr>\n","    <tr>\n","      <th>rating</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3957907</td>\n","      <td>3957907</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3855830</td>\n","      <td>3855830</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        user_id  anime_id\n","rating                   \n","0       3957907   3957907\n","1       3855830   3855830"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df.groupby(by=['rating']).count()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:15:38.542470Z","iopub.status.busy":"2024-09-25T16:15:38.542152Z","iopub.status.idle":"2024-09-25T16:15:42.460618Z","shell.execute_reply":"2024-09-25T16:15:42.459680Z","shell.execute_reply.started":"2024-09-25T16:15:38.542428Z"},"id":"ikedGzjXyW2F","trusted":true},"outputs":[],"source":["df_train, df_valid = model_selection.train_test_split(\n","    df, test_size=0.1, random_state=42, stratify=df.rating.values\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:15:55.934226Z","iopub.status.busy":"2024-09-25T16:15:55.933377Z","iopub.status.idle":"2024-09-25T16:15:56.125614Z","shell.execute_reply":"2024-09-25T16:15:56.124766Z","shell.execute_reply.started":"2024-09-25T16:15:55.934182Z"},"id":"4vA6_0_oyW2F","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>anime_id</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2824162</th>\n","      <td>26466</td>\n","      <td>5955</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3556926</th>\n","      <td>32936</td>\n","      <td>527</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>489764</th>\n","      <td>4992</td>\n","      <td>1726</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>35460</th>\n","      <td>392</td>\n","      <td>7592</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5615936</th>\n","      <td>52728</td>\n","      <td>3785</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         user_id  anime_id  rating\n","2824162    26466      5955       0\n","3556926    32936       527       0\n","489764      4992      1726       0\n","35460        392      7592       0\n","5615936    52728      3785       1"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df_train.head()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:15:56.127552Z","iopub.status.busy":"2024-09-25T16:15:56.127239Z","iopub.status.idle":"2024-09-25T16:15:56.133557Z","shell.execute_reply":"2024-09-25T16:15:56.132384Z","shell.execute_reply.started":"2024-09-25T16:15:56.127519Z"},"id":"srlcz6wwyW2F","trusted":true},"outputs":[],"source":["train_dataset = MovieDataset(\n","    users=df_train.user_id.values,\n","    movies=df_train.anime_id.values,\n","    ratings=df_train.rating.values\n",")\n","\n","val_dataset = MovieDataset(\n","    users=df_valid.user_id.values,\n","    movies=df_valid.anime_id.values,\n","    ratings=df_valid.rating.values\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-09-25T16:15:56.135334Z","iopub.status.busy":"2024-09-25T16:15:56.134936Z","iopub.status.idle":"2024-09-25T16:15:56.151549Z","shell.execute_reply":"2024-09-25T16:15:56.150731Z","shell.execute_reply.started":"2024-09-25T16:15:56.135301Z"},"id":"rjen-4ThyW2G","outputId":"939a9601-ff7a-445f-b26b-c8639ec69908","trusted":true},"outputs":[{"data":{"text/plain":["{'users': tensor(26466), 'movies': tensor(5955), 'rating': tensor(0)}"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["next(iter(train_dataset))"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:15:56.773510Z","iopub.status.busy":"2024-09-25T16:15:56.773129Z","iopub.status.idle":"2024-09-25T16:15:56.778846Z","shell.execute_reply":"2024-09-25T16:15:56.777914Z","shell.execute_reply.started":"2024-09-25T16:15:56.773473Z"},"id":"h5ucLAFbyW2G","trusted":true},"outputs":[],"source":["train_loader = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=64,\n","    shuffle=True,\n",")\n","\n","validation_loader = DataLoader(\n","    dataset=val_dataset,\n","    batch_size=1024*2,\n","    shuffle=True\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["34619"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["max(df.anime_id)+100"]},{"cell_type":"code","execution_count":260,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T18:00:02.988135Z","iopub.status.busy":"2024-09-25T18:00:02.987741Z","iopub.status.idle":"2024-09-25T18:00:03.159879Z","shell.execute_reply":"2024-09-25T18:00:03.158913Z","shell.execute_reply.started":"2024-09-25T18:00:02.988101Z"},"id":"gDlKu-XQyW2G","trusted":true},"outputs":[],"source":["model = RecSysModelWithDropout(\n","    users_buckets=max(df.user_id)+100,\n","    movies_buckets=max(df.anime_id)+100,\n",").to(device=device)\n","\n","optimizer = torch.optim.SparseAdam(model.parameters())"]},{"cell_type":"code","execution_count":163,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:16:03.578201Z","iopub.status.busy":"2024-09-25T16:16:03.577736Z","iopub.status.idle":"2024-09-25T16:16:03.583300Z","shell.execute_reply":"2024-09-25T16:16:03.581972Z","shell.execute_reply.started":"2024-09-25T16:16:03.578156Z"},"trusted":true},"outputs":[],"source":["loss_func = nn.BCELoss()"]},{"cell_type":"code","execution_count":224,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T16:16:10.334796Z","iopub.status.busy":"2024-09-25T16:16:10.334410Z","iopub.status.idle":"2024-09-25T16:16:10.354006Z","shell.execute_reply":"2024-09-25T16:16:10.352925Z","shell.execute_reply.started":"2024-09-25T16:16:10.334758Z"},"trusted":true},"outputs":[],"source":["def fit(model, optimizer, epochs, train_dataset, val_dataset, loss_fn, metric, device, callback={}, save_model=None):\n","\n","    '''callback = {\n","        \"ModelCheckpoint\": {\"filepath\":\"model_chkpt.pth\"},\n","        }'''\n","    \n","    if save_model:\n","        # Load the saved state dictionary\n","        model.load_state_dict(torch.load(save_model, map_location=device))\n","\n","            \n","    train_acc_metric = metric()#.to(device)  # Define the train accuracy metric.\n","    val_acc_metric = metric()#.to(device)  # Define the validation accuracy metric.\n","    model.to(device)  # send model to target device\n","    \n","    #### Training Step Function ***************\n","    def train_step(users, movies, labels):\n","        labels = labels.view(-1,).to(torch.float32)\n","        # model.train()  # set model to training mode\n","        optimizer.zero_grad()  # clear gradients\n","        predictions = model(users, movies)  # Forward pass. \n","        loss_value = loss_fn(predictions, labels)  # calculate loss\n","        loss_value.backward()  # Backward pass\n","        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)  # gradient clipping\n","        optimizer.step()  # Update weights\n","        train_acc_metric.update(labels, predictions.detach())  # update training metric\n","        return loss_value.detach().cpu().item()  # return training loss\n","    \n","    #### Validation Step Function ***************\n","    def test_step(users, movies, labels):\n","        labels = labels.view(-1, ).to(torch.float32)\n","        # model.eval()  # set model to evaluation mode\n","        with torch.inference_mode():  # turn off gradient\n","            val_predictions = model(users, movies)  # Forward pass\n","            val_acc_metric.update(labels, val_predictions)  # update validation metric\n","        return loss_fn(val_predictions, labels).cpu().item()  # return validation loss\n","\n","    history = {\"train_accuracy\":[], \"val_accuracy\":[], \"train_loss\":[], \"val_loss\":[]}  # history of train_acc, train_loss, vall_acc, val_loss.\n","    \n","    train_lenght = len(train_dataset)  #Define the length of the train dataset.\n","    val_length = len(val_dataset)\n","    \n","    #### Training Loop ***************\n","    for e in range(1, epochs+1):\n","        count = 0\n","        train_loss = 0  # Define the train loss.\n","        display = tqdm(train_dataset)  # display progress bar\n","        for i, batch in enumerate(display):\n","            batch_train_loss = train_step(batch['users'].to(device), batch['movies'].to(device), batch['rating'].to(device))\n","            train_loss += batch_train_loss/(i+1)                    \n","            display.set_description(f\"Epoch {e} Train Loss: {train_loss:.6f} Tain Accuracy: {train_acc_metric.compute():.6f}\")\n","            count += 1\n","            \n","            ### &&&&&&&&&&&&&&&&\n","            if count == 1000:\n","#                 scheduler.step()\n","                count = 0\n","        \n","                ### Define the monitor.    \n","                monitor = {\"train_\": train_acc_metric.compute(), \"train_loss\": train_loss}\n","\n","                ### define a wandb logger. @@@@@@@@@@@@@@@@@\n","#                 wandb.log(monitor)\n","\n","        #### Validation Loop ***************    \n","        val_loss = 0\n","        display1 = tqdm(val_dataset)\n","        for i, batch in enumerate(display1):\n","            val_loss += test_step(batch['users'].to(device), batch['movies'].to(device), batch['rating'].to(device))/(i+1)\n","            display1.set_description(f\"Val Loss: {val_loss :.6f} Val Accuracy: {val_acc_metric.compute():.6f}\")        \n","        \n","        \n","        history[\"train_accuracy\"].append(train_acc_metric.compute())  # Update the history of the training.\n","        history[\"val_accuracy\"].append(val_acc_metric.compute())  # Update the history of the validation.\n","        history[\"train_loss\"].append(train_loss)  # Update the history of the training.\n","        history[\"val_loss\"].append(val_loss)  # Update the history of the validation.\n","\n","        ### Define the monitor.    \n","        monitor = {\"val_\": val_acc_metric.compute(), \"train_\": train_acc_metric.compute(), \"val_loss\": val_loss, \"train_loss\": train_loss}\n","\n","        ### define a wandb logger. @@@@@@@@@@@@@@@@@\n","#         wandb.log(monitor)\n","        \n","        ####  ModelCheckpoint Callbacks ***************\n","        if callback.get(\"ModelCheckpoint\"):\n","            path = callback[\"ModelCheckpoint\"][\"filepath\"]  # path of the model.\n","            torch.save(model.state_dict(), path)  # Save the best model.\n","            print(\"Model is saved.\")\n","\n","        train_acc_metric.reset()  # reset training metric\n","        val_acc_metric.reset() ### reset validation metric\n","        \n","        print()  # new line\n","        \n","    return history  # Return the history.        "]},{"cell_type":"code","execution_count":171,"metadata":{},"outputs":[],"source":["# model.load_state_dict(torch.load('model_chkpt.pth', map_location=device))"]},{"cell_type":"code","execution_count":172,"metadata":{},"outputs":[],"source":["class Accuracy:\n","    def __init__(self):\n","        self.correct = 0\n","        self.total = 0\n","        \n","    def update(self, y_true, y_pred):\n","        y_pred = y_pred > 0.5\n","        self.correct += torch.eq(y_pred, y_true).sum().item()\n","        self.total += y_true.size(0)\n","    \n","    def compute(self):\n","        if self.total == 0:\n","            return 0\n","        return self.correct / self.total\n","    \n","    def reset(self):\n","        self.correct = 0\n","        self.total = 0"]},{"cell_type":"code","execution_count":273,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T19:30:07.224771Z","iopub.status.busy":"2024-09-25T19:30:07.224428Z","iopub.status.idle":"2024-09-25T19:40:07.933751Z","shell.execute_reply":"2024-09-25T19:40:07.932774Z","shell.execute_reply.started":"2024-09-25T19:30:07.224738Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1 Train Loss: 5.800163 Tain Accuracy: 0.767300: 100%|██████████| 109881/109881 [06:32<00:00, 279.89it/s]\n","Val Loss: 3.246384 Val Accuracy: 0.757738: 100%|██████████| 382/382 [00:10<00:00, 36.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Model is saved.\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 Train Loss: 5.795678 Tain Accuracy: 0.767321: 100%|██████████| 109881/109881 [06:48<00:00, 269.20it/s]\n","Val Loss: 3.252605 Val Accuracy: 0.757431: 100%|██████████| 382/382 [00:09<00:00, 38.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Model is saved.\n","\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 Train Loss: 5.823866 Tain Accuracy: 0.767619: 100%|██████████| 109881/109881 [07:15<00:00, 252.13it/s]\n","Val Loss: 3.257548 Val Accuracy: 0.758271: 100%|██████████| 382/382 [00:10<00:00, 35.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Model is saved.\n","\n"]}],"source":["history = fit(model=model, optimizer=optimizer, epochs=3, train_dataset=train_loader, \n","              val_dataset=validation_loader, loss_fn=loss_func, metric=Accuracy, \n","              device=device, callback={\"ModelCheckpoint\": {\"filepath\":\"model_chkpt.pth\"},}, save_model=None)"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T13:46:53.966271Z","iopub.status.busy":"2024-09-25T13:46:53.965891Z","iopub.status.idle":"2024-09-25T13:46:54.092270Z","shell.execute_reply":"2024-09-25T13:46:54.091365Z","shell.execute_reply.started":"2024-09-25T13:46:53.966232Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'train_accuracy': [tensor(0.4297, device='cuda:0')],\n"," 'val_accuracy': [tensor(0.3987, device='cuda:0')],\n"," 'train_loss': [10.184275003148612],\n"," 'val_loss': [7.5748745844218295]}"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["history"]},{"cell_type":"code","execution_count":274,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Threshold: 0.5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 382/382 [00:09<00:00, 38.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Precision: 0.7370\n","Recall: 0.7924\n"]}],"source":["def evaluate(model, validation_loader, th=0.5):\n","    y_true = []\n","    y_pred = []\n","\n","    # Turn off gradient calculations\n","    with torch.no_grad():\n","        display = tqdm(validation_loader)\n","        for i, batch in enumerate(display):\n","            user = batch['users']\n","            movie = batch['movies']\n","            rating = batch['rating'].float()  # Ensure the target is float\n","            \n","            # Get model predictions\n","            model_output = model(user, movie)\n","            predictions = (model_output > th).float()  # Convert to binary predictions (0 or 1)\n","            \n","            # Store the predictions and actual ratings\n","            y_true.extend(rating.cpu().numpy())  # True labels\n","            y_pred.extend(predictions.cpu().numpy())  # Predicted labels\n","\n","    # Compute precision and recall\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","\n","    print(f'Precision: {precision:.4f}')\n","    print(f'Recall: {recall:.4f}')\n","\n","for i in [0.50]:\n","    print(f\"Threshold: {i}\")\n","    evaluate(model, validation_loader, th=i)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5754851,"sourceId":9464790,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelId":125438,"modelInstanceId":101243,"sourceId":120366,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
